{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3조 소스코드.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N1h7dD7g1a_M",
        "pM3Wkg09zyG4",
        "SdOHcyi9z5IB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycb2aQOtcJNT"
      },
      "source": [
        "실전기계 학습 Face Age Estimation\n",
        "\n",
        "한정된 parameter에서 최고의 성능을 높이는 competition이었다.\n",
        "\n",
        "시도한 방법은\n",
        "\n",
        "1. 다양한 모델 (ResNet, Pre-Activation ResNet, WideResNet)\n",
        "\n",
        "2. kfold\n",
        "\n",
        "3. bsconv(경량화 conv 사용)\n",
        "\n",
        "4. ensemble\n",
        "\n",
        "5. optimizer 변경 (radam, adam, sgd)\n",
        "\n",
        "6. 스케쥴러 변경 (CosineAnnealingWarmupRestarts, multi step etc)\n",
        "\n",
        "7. 전처리 (dataset balance를 위해 upsample)\n",
        "\n",
        "8. data augmentation, albumentations 사용\n",
        "\n",
        "그중 3번 4번 8번이 가장 효과가 좋았다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW-ku5BrRh0r",
        "outputId": "31a82c5a-8705-4e76-9d6d-b767f2544efd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 12 07:48:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7lSurxQyvLl",
        "outputId": "0bfa1585-ff96-4cc4-f3c5-70f02fe2e6c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_GzktGo0Iy2"
      },
      "source": [
        "!mkdir ./dataset\n",
        "!unzip /content/drive/MyDrive/FaceAge.zip -d ./dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1h7dD7g1a_M"
      },
      "source": [
        "##**Import all neceassary packages**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoBDhGbdAhV4",
        "outputId": "0792114b-7d09-46a9-ddba-e81e01ac76eb"
      },
      "source": [
        "!pip install --upgrade bsconv\n",
        "!pip install -U albumentations\n",
        "!pip install pytorchcv torch>=0.4.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bsconv\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/2b/c1e85d364217884e13809649150e3e790f0a79fdb576bdbbae6745c34e58/bsconv-0.4.0-py3-none-any.whl\n",
            "Installing collected packages: bsconv\n",
            "Successfully installed bsconv-0.4.0\n",
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/be/3db3cd8af771988748f69eace42047d5edebf01eaa7e1293f3b3f75f989e/albumentations-1.0.0-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Installing collected packages: opencv-python-headless, albumentations\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.0.0 opencv-python-headless-4.5.2.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iXqzVdl1W7g"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import bsconv.pytorch\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM3Wkg09zyG4"
      },
      "source": [
        "##**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNtqlF4zv0Y"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "# def accuracy(output, target, topk=(1,)):\n",
        "#     r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "#     \"\"\"\n",
        "#     with torch.no_grad():\n",
        "#         maxk = max(topk)\n",
        "#         batch_size = target.size(0)\n",
        "\n",
        "#         # _, pred = output.topk(maxk, 1, True, True)\n",
        "#         # pred = pred.t()\n",
        "#         # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "#         # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
        "#         _, idx = output.sort(descending=True)\n",
        "#         pred = idx[:,:maxk]\n",
        "#         pred = pred.t()\n",
        "#         correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "#         res = []\n",
        "#         for k in topk:\n",
        "#             correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "#             res.append(correct_k.mul_(100.0 / batch_size))\n",
        "#         return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c_r2ihZmf2U"
      },
      "source": [
        "import random\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvMAGIFk1e-G"
      },
      "source": [
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi6qeD0l2_Pl"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
        "    \"\"\"\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        first_cycle_steps (int): First cycle step size.\n",
        "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
        "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
        "        min_lr(float): Min learning rate. Default: 0.001.\n",
        "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
        "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 optimizer : torch.optim.Optimizer,\n",
        "                 first_cycle_steps : int,\n",
        "                 cycle_mult : float = 1.,\n",
        "                 max_lr : float = 0.1,\n",
        "                 min_lr : float = 0.001,\n",
        "                 warmup_steps : int = 0,\n",
        "                 gamma : float = 1.,\n",
        "                 last_epoch : int = -1\n",
        "        ):\n",
        "        assert warmup_steps < first_cycle_steps\n",
        "        \n",
        "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
        "        self.base_max_lr = max_lr # first max learning rate\n",
        "        self.max_lr = max_lr # max learning rate in the current cycle\n",
        "        self.min_lr = min_lr # min learning rate\n",
        "        self.warmup_steps = warmup_steps # warmup step size\n",
        "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
        "        \n",
        "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle = 0 # cycle count\n",
        "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
        "        \n",
        "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "        # set learning rate min_lr\n",
        "        self.init_lr()\n",
        "    \n",
        "    def init_lr(self):\n",
        "        self.base_lrs = []\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.min_lr\n",
        "            self.base_lrs.append(self.min_lr)\n",
        "    \n",
        "    def get_lr(self):\n",
        "        if self.step_in_cycle == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.step_in_cycle < self.warmup_steps:\n",
        "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.max_lr - base_lr) \\\n",
        "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
        "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.step_in_cycle = self.step_in_cycle + 1\n",
        "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
        "                self.cycle += 1\n",
        "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
        "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
        "        else:\n",
        "            if epoch >= self.first_cycle_steps:\n",
        "                if self.cycle_mult == 1.:\n",
        "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
        "                    self.cycle = epoch // self.first_cycle_steps\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
        "                    self.cycle = n\n",
        "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
        "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
        "            else:\n",
        "                self.cur_cycle_steps = self.first_cycle_steps\n",
        "                self.step_in_cycle = epoch\n",
        "                \n",
        "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHo4rPXoC_Sx"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        \n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
        "            for param in params:\n",
        "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
        "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = group['buffer'][int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    elif self.degenerated_to_sgd:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = -1\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "                elif step_size > 0:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY35l51Oz1LI"
      },
      "source": [
        "##**Parameter Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KthoIw1bz16r"
      },
      "source": [
        "batch_size = 32  # Input batch size for training (default: 128)\n",
        "epochs = 100 # Number of epochs to train (default: 100)\n",
        "print_freq = 200\n",
        "num_workers = 4\n",
        "train_size = 0.9 #valid 10%\n",
        "patience = 8\n",
        "image_size = 48\n",
        "seed_everything(84465)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdOHcyi9z5IB"
      },
      "source": [
        "##**Load and preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Gu0sRd8wGs"
      },
      "source": [
        "\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(image_size, image_size), \n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "\n",
        "        A.CoarseDropout(max_holes= 4,max_height=8,max_width=8),\n",
        "        # A.RandomGamma(),\n",
        "        # A.GridDistortion(distort_limit=(-0.3, 0.3), border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
        "        A.ElasticTransform(alpha_affine=2, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
        "\n",
        "        # A.geometric.rotate.Rotate(limit=30),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "         A.Resize(48, 48), \n",
        "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9COdKRKByQy"
      },
      "source": [
        "from torch.utils.data import Dataset,Subset\n",
        "\n",
        "\n",
        "class FacialDataset(Dataset):\n",
        "    def __init__(self, data_path,transform):\n",
        "        if not os.path.exists(data_path):\n",
        "            raise Exception(f\"[!] {data_path} not existed\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self.data_path = data_path\n",
        "        self.age_path = sorted(glob(os.path.join(data_path, \"*.*\")))\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.age_path[idx]\n",
        "\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = int(image_filepath.split('_')[0].split('/')[-1])\n",
        "\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.age_path)\n",
        "\n",
        "data_path =\"/content/dataset/train\"\n",
        "train_dataset = FacialDataset(data_path,train_transform)\n",
        "valid_dataset = FacialDataset(data_path,test_transform)\n",
        "\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(train_size * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, valid_idx = indices[:split], indices[split:]\n",
        "\n",
        "traindata = Subset(train_dataset, indices=train_idx)\n",
        "valdata = Subset(valid_dataset, indices=valid_idx)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=traindata,batch_size=batch_size,shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=valdata,batch_size=batch_size,shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_TpgM8NM86e",
        "outputId": "fa686263-c74a-48dc-9287-d96dbd4eb83a"
      },
      "source": [
        "train_loader.sampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.sampler.RandomSampler at 0x7f22f40a9290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FaaVWe1EinH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357144d8-f949-4e5c-db6e-55c7f21ded91"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "# functions to show an image\n",
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[0],nrow=20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YjQ5H163hQi"
      },
      "source": [
        "##**Main Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJX_-Qy3gup"
      },
      "source": [
        "def train(train_loader, epoch, model, optimizer):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    l2 = AverageMeter('L2 Loss', ':.4f')\n",
        "    rmse = AverageMeter('RMSE Loss', ':.4f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, l2,rmse, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    l2_criterion = nn.MSELoss().cuda()\n",
        "    end = time.time()\n",
        "    for i, (input, label) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        input = input.float().cuda()\n",
        "        label = label.float().flatten().cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input).flatten()\n",
        "  \n",
        "        loss = l2_criterion(output, label)\n",
        "        rmse_loss = torch.sqrt(loss)\n",
        "\n",
        "\n",
        "        #BSconv-s\n",
        "        # loss +=model.reg_loss(alpha=0.1)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        rmse_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        #loss updaet\n",
        "        l2.update(loss.item(), input.size(0))\n",
        "        rmse.update(rmse_loss.item(), input.size(0))\n",
        "        \n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def validation(val_loader,epoch, model):\n",
        "    print(\"Vlaid \",end=\"\")\n",
        "    model.eval()\n",
        "    l2_criterion = nn.MSELoss().cuda()\n",
        "\n",
        "    l2 = AverageMeter('L2 Loss', ':.4f')\n",
        "    rmse = AverageMeter('RMSE Loss', ':.4f')\n",
        "    progress = ProgressMeter(len(val_loader), l2,rmse,  prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for i,(input,label) in enumerate(val_loader):\n",
        "          input = input.float().cuda()\n",
        "          label = label.float().flatten().cuda()\n",
        "          output = model(input).flatten()\n",
        "          l2_ = l2_criterion(output, label)\n",
        "          table = (torch.round(output) == label)\n",
        "          correct += (table).float().sum()\n",
        "          l2.update(l2_.item(), input.size(0))\n",
        "          rmse.update(torch.sqrt(l2_).item(), input.size(0))\n",
        "\n",
        "      progress.print(len(val_loader))\n",
        "      return rmse.avg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5fc6anbkjG-"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FQhbWspS2bD"
      },
      "source": [
        "\n",
        "\n",
        "model  = bsconv.pytorch.get_model('cifar_wrn40_4_bsconvu', num_classes=1).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer,\n",
        "    mode='min',\n",
        "    patience=2,\n",
        "    factor=0.5,\n",
        "    verbose=True\n",
        "    )\n",
        "\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {pytorch_total_params}\")\n",
        "if int(pytorch_total_params) > 2000000:\n",
        "    print('Your model has the number of parameters more than 2 millions..')\n",
        "    sys.exit()\n",
        "\n",
        "loss = 1e5\n",
        "_patience = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "\n",
        "    train(train_loader, epoch, model, optimizer)\n",
        "    val_loss = validation(val_loader,epoch,model)\n",
        "\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Save model for best \n",
        "    if loss > val_loss:\n",
        "        loss = val_loss\n",
        "        print(f\"Best model save | loss : {loss:.4f}\")\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "        _patience = 0\n",
        "    else:\n",
        "        _patience += 1\n",
        "        if _patience > patience - 1:\n",
        "            print('=======' * 10)\n",
        "            print(\"[Info message] Early stopper is activated\")\n",
        "            break\n",
        "\n",
        "    torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best RMSE loss: {loss}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEjjfaddeQT7"
      },
      "source": [
        "## Make an evalutation csv file\n",
        "\n",
        "This code makes an evaluation csv file for Competition submission.\n",
        "\n",
        "**Don't change below code!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RShha2GePNH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bea1d6c9-a6ab-4dc4-aa2b-545f441fc34e"
      },
      "source": [
        "class FacialDataset_test(Dataset):\n",
        "    def __init__(self, data_path,transform):\n",
        "        if not os.path.exists(data_path):\n",
        "            raise Exception(f\"[!] {data_path} not existed\")\n",
        "\n",
        "        self.transform = transform\n",
        "        self.data_path = data_path\n",
        "        self.age_path = sorted(glob(os.path.join(data_path, \"*.*\")))\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.age_path[idx]\n",
        "\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        return image\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.age_path)\n",
        "\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import time\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "def eval():\n",
        "    test_dataset = FacialDataset_test(\"/content/dataset/test\",test_transform)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=1,shuffle=False)\n",
        "\n",
        "    model  = bsconv.pytorch.get_model('cifar_wrn40_4_bsconvu', num_classes=1).cuda()\n",
        "  \n",
        "    model.load_state_dict(torch.load('/content/model_best.pt'))\n",
        "    model.eval()\n",
        "    \n",
        "    print('Make an evaluation csv file for submission...')\n",
        "    Category = []\n",
        "    for input in test_loader:\n",
        "        input = input.float().cuda()\n",
        "        output = [model(input).item()]\n",
        "        # output = torch.argmax(output, dim=1)\n",
        "        Category = Category + output\n",
        "\n",
        "    Id = list(range(0, len(test_loader)))\n",
        "    samples = {\n",
        "       'Id': Id,\n",
        "       'Category': Category \n",
        "    }\n",
        "    df = pd.DataFrame(samples, columns=['Id', 'Category'])\n",
        "\n",
        "    df.to_csv('/content/submission_best.csv', index=False)\n",
        "    print('Done!!')\n",
        "\n",
        "  \n",
        "if __name__ == \"__main__\":\n",
        "    eval()\n",
        "    files.download('submission_best.csv') \n",
        "    files.download('model_best.pt') \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Make an evaluation csv file for submission...\n",
            "Done!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fcd0cfad-c142-443c-be0f-8f10fcc5da3f\", \"submission_best.csv\", 254066)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_061bb18f-12fe-40c2-ad25-f99a17879809\", \"model_best.pt\", 4510052)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}